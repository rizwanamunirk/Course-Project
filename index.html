<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Event Based Home Localization</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <!-- Header Section -->
  <header class="header">
    <h1>Course Project: Event Based Home Localization</h1>
    <p>Welcome to my project webpage. Below, you'll find all the materials related to this project.</p>
  </header>

  <!-- Introduction Section -->
  <section id="introduction" class="section">
    <h2>Introduction</h2>
    <p>In this work, we present a bio-inspired approach
for home localization using event-based visual data and spiking
convolutional neural networks (S-CNNs) in a simulated environ-
ment within NVIDIA Omniverse. Inspired by the navigational
strategies of insects, which rely on sparse and efficient neural
computations, we utilize event cameras to capture dynamic, asyn-
chronous image data that emulates insect-like visual processing.
The proposed system employs a spiking convolutional neural
network trained to encode relative home vectors based on the
unit-circle representation of gaze directions, as outlined in recent
studies. By leveraging the event-based nature of the data, the
S-CNN efficiently processes temporal changes in the environ-
ment, ensuring robustness to lighting variations and dynamic
scenes. Using a quadrotor equipped with an event camera, we
demonstrate our approach in a 3D environment modeled with
realistic terrain and obstacles, where the quadrotor autonomously
navigates back to a designated ”nest” location. Comparative
results with conventional frame-based neural networks highlight
the efficiency and accuracy of the proposed system in localizing
the home under varying conditions. This study establishes a
novel framework for integrating event-based data and spiking
neural networks for real-time, energy-efficient localization tasks
in robotics. Comparative results with conventional frame-based
neural networks highlight the efficiency and accuracy of the
proposed system in localizing the home under varying conditions.
Future work will explore the deployment of the system in a multi-
quadrotor environment to coordinate collaborative tasks, the
integration of multi-modal sensory inputs such as Camera, IMU,
Gas sensors and GPS data, and the extension of the framework
to real-world settings for further validation and scalability</p>
  </section>

  <!-- Materials Section -->
  <section id="materials" class="section">
    <h2>Project Materials</h2>
    <ul class="materials-list">
      <li><a href="Report.pdf" target="_blank">Project Report (PDF)</a></li>
      <li><a href="Codes.zip" target="_blank">Source Codes(Zip)</a></li>
      <li><a href="Pictures.zip" download>Project Screenshots (Download ZIP)</a></li>
      <li><a href="Videos.zip" target="_blank">Videos</a></li>
    </ul>
  </section>

  <!-- Footer Section -->
  <footer class="footer">
    <p>Created by [Rizwana Kausar]. Contact: <a href="mailto:100062832@ku.ac.ae">100062832@ku.ac.ae</a></p>
    <p>&copy; 2024 [Rizwana Kausar]. All rights reserved.</p>
  </footer>
</body>
</html>
